{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import random\n",
    "from time import sleep\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Lambda, Input, Flatten, Dropout, Embedding, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '5PZFMN4UIV66SBO6A1KE'\n",
    "base_url = 'http://35.180.178.243'\n",
    "url_reset = base_url + '/reset'\n",
    "url_predict = base_url + '/predict'\n",
    "params = {'user_id': user_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json file\n",
    "r = requests.get(url=url_reset, params=params)\n",
    "data = r.json()\n",
    "\n",
    "nb_items = data['nb_items']\n",
    "nb_users = data['nb_users']\n",
    "\n",
    "action_history = data['action_history']\n",
    "rewards_history = data['rewards_history']\n",
    "state_history = data['state_history']\n",
    "\n",
    "next_state = data['next_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history 200\n",
    "# action history : recommended item position\n",
    "# reward history : 0 or price\n",
    "# state history \n",
    "# state[j][0] = user\n",
    "# state[j][1] = item\n",
    "# state[j][2] = price\n",
    "# state[j][3:] = variables\n",
    "\n",
    "# data.keys()\n",
    "# len(action_history), len(rewards_history), len(state_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline, random\n",
    "def model_zero(state):\n",
    "    length = len(state)\n",
    "    return np.random.randint(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most expensive\n",
    "def model_one(state):\n",
    "    length = len(state)\n",
    "    price = 0\n",
    "    item = 0\n",
    "    for i in range(length):\n",
    "        p = state[i][2]\n",
    "        if p > price:\n",
    "            price = p\n",
    "            item = i\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    \n",
    "    # independent with y_true\n",
    "    # insistant to reduce y_pred\n",
    "    return tf.reduce_mean(y_pred + 0 * y_true)\n",
    "\n",
    "def triplet_loss(inputs, alpha=0.2):\n",
    "    pos_sim, neg_sim = inputs\n",
    "    return tf.maximum(neg_sim - pos_sim + alpha, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent model, siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_two:\n",
    "    def __init__(self, nb_users, nb_items):\n",
    "        self.nb_users = nb_users\n",
    "        self.nb_items = nb_items\n",
    "        \n",
    "        self.epsilon = 0.99  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.95\n",
    "        \n",
    "        self.pred_model, self.triplet_model = self._build_model()\n",
    "        self.triplet_model.compile(loss=identity_loss, optimizer='adam')\n",
    "        \n",
    "    def _build_model(self):\n",
    "        user_id_input = Input(shape=[1], name='user')\n",
    "        item_id_input = Input(shape=[1], name='item')\n",
    "        variable_input = Input(shape=[5], name='variable')\n",
    "\n",
    "        user_embedding = Embedding(output_dim=10, input_dim=self.nb_users+1,\n",
    "                                   input_length=1, name='user_embedding')(user_id_input)\n",
    "        \n",
    "        item_embedding = Embedding(output_dim=10, input_dim=self.nb_items+1,\n",
    "                                   input_length=1, name='item_embedding')(item_id_input)\n",
    "            \n",
    "        \n",
    "        user_vecs = Flatten()(user_embedding)\n",
    "        item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "        cc = Concatenate()([user_vecs, item_vecs, variable_input])\n",
    "\n",
    "        y1 = Dense(50, activation='relu')(cc)\n",
    "        y2 = Dense(30, activation='relu')(y1)\n",
    "        d = Dropout(0.5)(y2)\n",
    "        y3 = Dense(1, activation='sigmoid')(d)\n",
    "        \n",
    "        model = Model(inputs=[user_id_input, item_id_input, variable_input], outputs=y3)\n",
    "\n",
    "        # siamese network \n",
    "        input1_user = Input(shape=[1])  # 1: positive\n",
    "        input2_user = Input(shape=[1])  # 2: negative\n",
    "        \n",
    "        input1_item = Input(shape=[1])\n",
    "        input2_item = Input(shape=[1])\n",
    "        \n",
    "        input1_variable = Input(shape=[5])\n",
    "        input2_variable = Input(shape=[5])\n",
    "    \n",
    "        \n",
    "        prob1 = model([input1_user, input1_item, input1_variable])\n",
    "        prob2 = model([input2_user, input2_item, input2_variable])\n",
    "        \n",
    "        tri_loss = Lambda(triplet_loss, output_shape=(1,))([prob1, prob2])\n",
    "        \n",
    "        triplet_model = Model(inputs=[input1_user, input1_item, input1_variable, \n",
    "                                      input2_user, input2_item, input2_variable],\n",
    "                              outputs=tri_loss)\n",
    "\n",
    "        return model, triplet_model\n",
    "\n",
    "    def predict(self, state):\n",
    "        length = len(state)\n",
    "        \n",
    "        decision = np.zeros(length)\n",
    "        for i in range(length):\n",
    "            prob = self.pred_model.predict([np.array([next_state[i][0]]), \n",
    "                                            np.array([next_state[i][1]]),\n",
    "                                            np.array([next_state[i][3:]])])\n",
    "            decision[i] = prob\n",
    "        return np.argmax(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    r = requests.get(url=url_reset, params=params)\n",
    "    data = r.json()\n",
    "\n",
    "    nb_items = data['nb_items']\n",
    "    nb_users = data['nb_users']\n",
    "\n",
    "    action_history = data['action_history']\n",
    "    rewards_history = data['rewards_history']\n",
    "    state_history = data['state_history']\n",
    "\n",
    "    next_state = data['next_state']\n",
    "    \n",
    "    # split positive and negative examples\n",
    "    pos_user = []\n",
    "    neg_user = []\n",
    "    pos_item = []\n",
    "    neg_item = []\n",
    "    pos_variable = []\n",
    "    neg_variable = []\n",
    "    \n",
    "\n",
    "    for i in range(200):\n",
    "        action = action_history[i]\n",
    "        reward = rewards_history[i]\n",
    "        tmp = state_history[i][action]\n",
    "        variable = tmp[3:]\n",
    "        if reward > 0:\n",
    "            pos_user.append(tmp[0])\n",
    "            pos_item.append(tmp[1])\n",
    "            pos_variable.append(variable)\n",
    "        else:\n",
    "            neg_user.append(tmp[0])\n",
    "            neg_item.append(tmp[1])\n",
    "            neg_variable.append(variable)\n",
    "            \n",
    "    return next_state, pos_user, pos_item, pos_variable, neg_user, neg_item, neg_variable\n",
    "\n",
    "\n",
    "def sample_triplets(pos_user, pos_item, pos_variable, neg_user, neg_item, neg_variable):\n",
    "    sub_pos_user = []\n",
    "    sub_pos_item = []\n",
    "    sub_pos_variable = []\n",
    "    \n",
    "    num_pos = len(pos_user)\n",
    "    num_neg = len(neg_user)\n",
    "\n",
    "    for i in range(num_neg):\n",
    "        l = np.random.randint(num_pos)\n",
    "        sub_pos_user.append(pos_user[l])\n",
    "        sub_pos_item.append(pos_item[l])\n",
    "        sub_pos_variable.append(pos_variable[l])\n",
    "    fake_y = np.ones(num_neg)\n",
    "    return [sub_pos_user, sub_pos_item, sub_pos_variable, neg_user, neg_item, neg_variable], fake_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, pos_user, pos_item, pos_variable, neg_user, neg_item, neg_variable = reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 1s 7ms/step - loss: 0.2157 - val_loss: 0.1641\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 80us/step - loss: 0.2188 - val_loss: 0.1760\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 93us/step - loss: 0.1889 - val_loss: 0.1832\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 107us/step - loss: 0.1747 - val_loss: 0.1863\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 177us/step - loss: 0.1985 - val_loss: 0.1704\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 98us/step - loss: 0.1888 - val_loss: 0.1831\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 139us/step - loss: 0.1792 - val_loss: 0.1808\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 129us/step - loss: 0.2085 - val_loss: 0.1739\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 109us/step - loss: 0.1788 - val_loss: 0.1890\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 122us/step - loss: 0.1788 - val_loss: 0.1764\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 112us/step - loss: 0.1631 - val_loss: 0.1776\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.1764 - val_loss: 0.1925\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 115us/step - loss: 0.1808 - val_loss: 0.1852\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 129us/step - loss: 0.1796 - val_loss: 0.1665\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 138us/step - loss: 0.1577 - val_loss: 0.1795\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 105us/step - loss: 0.1693 - val_loss: 0.1884\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 116us/step - loss: 0.1485 - val_loss: 0.1598\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 154us/step - loss: 0.1698 - val_loss: 0.1753\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 146us/step - loss: 0.1871 - val_loss: 0.1619\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 127us/step - loss: 0.1577 - val_loss: 0.1914\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 116us/step - loss: 0.1579 - val_loss: 0.1659\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 128us/step - loss: 0.1462 - val_loss: 0.1723\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 127us/step - loss: 0.1484 - val_loss: 0.1815\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 112us/step - loss: 0.1577 - val_loss: 0.1791\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 108us/step - loss: 0.1321 - val_loss: 0.1635\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 121us/step - loss: 0.1396 - val_loss: 0.1698\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 104us/step - loss: 0.1270 - val_loss: 0.1637\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 115us/step - loss: 0.1359 - val_loss: 0.1644\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 88us/step - loss: 0.1214 - val_loss: 0.1384\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 118us/step - loss: 0.1099 - val_loss: 0.1214\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 110us/step - loss: 0.1100 - val_loss: 0.1334\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 81us/step - loss: 0.1031 - val_loss: 0.1280\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 89us/step - loss: 0.0983 - val_loss: 0.1317\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 113us/step - loss: 0.0897 - val_loss: 0.1504\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 83us/step - loss: 0.0923 - val_loss: 0.1542\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 89us/step - loss: 0.0787 - val_loss: 0.1311\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 123us/step - loss: 0.0706 - val_loss: 0.1335\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 104us/step - loss: 0.0763 - val_loss: 0.1439\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 105us/step - loss: 0.0670 - val_loss: 0.1158\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 99us/step - loss: 0.0634 - val_loss: 0.1024\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 96us/step - loss: 0.0767 - val_loss: 0.1344\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 128us/step - loss: 0.0651 - val_loss: 0.1200\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 113us/step - loss: 0.0740 - val_loss: 0.1037\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 111us/step - loss: 0.0558 - val_loss: 0.1525\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 134us/step - loss: 0.0540 - val_loss: 0.1081\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 100us/step - loss: 0.0395 - val_loss: 0.1044\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 105us/step - loss: 0.0396 - val_loss: 0.1098\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 108us/step - loss: 0.0390 - val_loss: 0.0949\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 99us/step - loss: 0.0291 - val_loss: 0.1122\n",
      "Train on 119 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "119/119 [==============================] - 0s 104us/step - loss: 0.0358 - val_loss: 0.0687\n"
     ]
    }
   ],
   "source": [
    "model_two = Model_two(nb_users, nb_items)\n",
    "\n",
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    triplet_inputs, fake_y = sample_triplets(pos_user, pos_item, pos_variable, \n",
    "                                             neg_user, neg_item, neg_variable)\n",
    "    \n",
    "    model_two.triplet_model.fit(triplet_inputs, fake_y, \n",
    "                                shuffle=True, batch_size=32,\n",
    "                                validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "change predict rule: highest reward esperance    \n",
    "add exploration   \n",
    "add online training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_three(Model_two):\n",
    "    def __init__(self, nb_users, nb_items):\n",
    "        Model_two.__init__(self, nb_users, nb_items)\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "    def predict(self, state):\n",
    "        self.last_state = state\n",
    "        length = len(state)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # exploration\n",
    "            action = model_one(next_state)\n",
    "            self.last_action = action\n",
    "            return action\n",
    "        \n",
    "        else:\n",
    "            # exploitation\n",
    "            decision = np.zeros(length)\n",
    "            price = np.zeros(length)\n",
    "            for i in range(length):\n",
    "                prob = self.pred_model.predict([np.array([next_state[i][0]]), \n",
    "                                                np.array([next_state[i][1]]),\n",
    "                                                np.array([next_state[i][3:]])])\n",
    "                decision[i] = prob\n",
    "                price[i] = state[i][2]\n",
    "            action = np.argmax(decision*price)\n",
    "            self.last_action = action\n",
    "            return action\n",
    "    \n",
    "    def retrain(self, reward):\n",
    "        user_id = np.array([self.last_state[self.last_action][0]])\n",
    "        item_id = np.array([self.last_state[self.last_action][1]])\n",
    "        variable = np.array([self.last_state[self.last_action][3:]])\n",
    "\n",
    "        prob = self.pred_model.predict([user_id, item_id, variable])\n",
    "        if reward > 0:\n",
    "            new_prob = prob * 1.02\n",
    "        else:\n",
    "            new_prob = prob * 0.98\n",
    "        self.pred_model.fit([user_id, item_id, variable], new_prob, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, pos_user, pos_item, pos_variable, neg_user, neg_item, neg_variable = reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 1s 7ms/step - loss: 0.2093 - val_loss: 0.1989\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 104us/step - loss: 0.1879 - val_loss: 0.1775\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 116us/step - loss: 0.1842 - val_loss: 0.1870\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 137us/step - loss: 0.1623 - val_loss: 0.1721\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 112us/step - loss: 0.1591 - val_loss: 0.1504\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 98us/step - loss: 0.1611 - val_loss: 0.1419\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 142us/step - loss: 0.1548 - val_loss: 0.1448\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 126us/step - loss: 0.1530 - val_loss: 0.1467\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 125us/step - loss: 0.1419 - val_loss: 0.1466\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 102us/step - loss: 0.1350 - val_loss: 0.1480\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 110us/step - loss: 0.1424 - val_loss: 0.1279\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 113us/step - loss: 0.1538 - val_loss: 0.1423\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 103us/step - loss: 0.1358 - val_loss: 0.1060\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 110us/step - loss: 0.1281 - val_loss: 0.1132\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 119us/step - loss: 0.1226 - val_loss: 0.1014\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 111us/step - loss: 0.1175 - val_loss: 0.1000\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 119us/step - loss: 0.1293 - val_loss: 0.1098\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 128us/step - loss: 0.1337 - val_loss: 0.0951\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 163us/step - loss: 0.1267 - val_loss: 0.1145\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 133us/step - loss: 0.1164 - val_loss: 0.1155\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 114us/step - loss: 0.1084 - val_loss: 0.1062\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 119us/step - loss: 0.1106 - val_loss: 0.1156\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 107us/step - loss: 0.1216 - val_loss: 0.0868\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 129us/step - loss: 0.1066 - val_loss: 0.0686\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 123us/step - loss: 0.0923 - val_loss: 0.0853\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 131us/step - loss: 0.0817 - val_loss: 0.0827\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 170us/step - loss: 0.0974 - val_loss: 0.0676\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 143us/step - loss: 0.1013 - val_loss: 0.1014\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 167us/step - loss: 0.0988 - val_loss: 0.0651\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 162us/step - loss: 0.0898 - val_loss: 0.0844\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 190us/step - loss: 0.0757 - val_loss: 0.0617\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 99us/step - loss: 0.0791 - val_loss: 0.0564\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 142us/step - loss: 0.0900 - val_loss: 0.0609\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 85us/step - loss: 0.0796 - val_loss: 0.0464\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 125us/step - loss: 0.0662 - val_loss: 0.0462\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 123us/step - loss: 0.0707 - val_loss: 0.0503\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 98us/step - loss: 0.0695 - val_loss: 0.0508\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 99us/step - loss: 0.0531 - val_loss: 0.0553\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 129us/step - loss: 0.0578 - val_loss: 0.0359\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 140us/step - loss: 0.0503 - val_loss: 0.0417\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 137us/step - loss: 0.0516 - val_loss: 0.0450\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 95us/step - loss: 0.0568 - val_loss: 0.0585\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 96us/step - loss: 0.0473 - val_loss: 0.0412\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 107us/step - loss: 0.0468 - val_loss: 0.0550\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 107us/step - loss: 0.0474 - val_loss: 0.0594\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 100us/step - loss: 0.0528 - val_loss: 0.0502\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 102us/step - loss: 0.0422 - val_loss: 0.0358\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 140us/step - loss: 0.0340 - val_loss: 0.0530\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 118us/step - loss: 0.0411 - val_loss: 0.0251\n",
      "Train on 129 samples, validate on 15 samples\n",
      "Epoch 1/1\n",
      "129/129 [==============================] - 0s 212us/step - loss: 0.0372 - val_loss: 0.0287\n"
     ]
    }
   ],
   "source": [
    "model_three = Model_three(nb_users, nb_items)\n",
    "\n",
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    triplet_inputs, fake_y = sample_triplets(pos_user, pos_item, pos_variable, \n",
    "                                             neg_user, neg_item, neg_variable)\n",
    "    \n",
    "    model_three.triplet_model.fit(triplet_inputs, fake_y, \n",
    "                                shuffle=True, batch_size=32,\n",
    "                                validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rate is: 0.286\n",
      "Average reward is: 141.67441928488992\n"
     ]
    }
   ],
   "source": [
    "episodes = 1000\n",
    "reward = 0\n",
    "rate = 0\n",
    "params = {'user_id': user_id, 'recommended_item':0}\n",
    "\n",
    "for i in range(episodes):\n",
    "    sleep(0.02)\n",
    "    \n",
    "    # predict next state\n",
    "    prediction = model_zero(next_state)\n",
    "    \n",
    "    # transmission with server\n",
    "    params['recommended_item'] = prediction\n",
    "    r = requests.get(url=url_predict, params=params)\n",
    "    d = r.json()\n",
    "\n",
    "    # conversion rate and reward\n",
    "    if d['reward'] > 0:\n",
    "        rate += 1\n",
    "        reward += d['reward']\n",
    "    \n",
    "    # update next state\n",
    "    next_state = d['state']\n",
    "    \n",
    "print('Conversion rate is:', rate/episodes)\n",
    "print('Average reward is:', reward/episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rate is: 0.218\n",
      "Average reward is: 201.12549890726584\n"
     ]
    }
   ],
   "source": [
    "episodes = 1000\n",
    "reward = 0\n",
    "rate = 0\n",
    "params = {'user_id': user_id, 'recommended_item':0}\n",
    "\n",
    "for i in range(episodes):\n",
    "    sleep(0.02)\n",
    "    \n",
    "    # predict next state\n",
    "    prediction = model_one(next_state)\n",
    "    \n",
    "    # transmission with server\n",
    "    params['recommended_item'] = prediction\n",
    "    r = requests.get(url=url_predict, params=params)\n",
    "    d = r.json()\n",
    "\n",
    "    # conversion rate and reward\n",
    "    if d['reward'] > 0:\n",
    "        rate += 1\n",
    "        reward += d['reward']\n",
    "    \n",
    "    # update next state\n",
    "    next_state = d['state']\n",
    "    \n",
    "print('Conversion rate is:', rate/episodes)\n",
    "print('Average reward is:', reward/episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rate is: 0.365\n",
      "Average reward is: 162.72465993892374\n"
     ]
    }
   ],
   "source": [
    "episodes = 1000\n",
    "reward = 0\n",
    "rate = 0\n",
    "params = {'user_id': user_id, 'recommended_item':0}\n",
    "\n",
    "for i in range(episodes):\n",
    "    sleep(0.02)\n",
    "    \n",
    "    # predict next state\n",
    "    prediction = model_two.predict(next_state)\n",
    "    \n",
    "    # transmission with server\n",
    "    params['recommended_item'] = prediction\n",
    "    r = requests.get(url=url_predict, params=params)\n",
    "    d = r.json()\n",
    "\n",
    "    # conversion rate and reward\n",
    "    if d['reward'] > 0:\n",
    "        rate += 1\n",
    "        reward += d['reward']\n",
    "    \n",
    "    # update next state\n",
    "    next_state = d['state']\n",
    "    \n",
    "print('Conversion rate is:', rate/episodes)\n",
    "print('Average reward is:', reward/episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion rate is: 0.296\n",
      "Average reward is: 267.35459797169693\n"
     ]
    }
   ],
   "source": [
    "episodes = 1000\n",
    "reward = 0\n",
    "rate = 0\n",
    "params = {'user_id': user_id, 'recommended_item':0}\n",
    "\n",
    "for i in range(episodes):\n",
    "    sleep(0.02)\n",
    "    \n",
    "    # predict next state\n",
    "    prediction = model_three.predict(next_state)\n",
    "    \n",
    "    # transmission with server\n",
    "    params['recommended_item'] = prediction\n",
    "    r = requests.get(url=url_predict, params=params)\n",
    "    d = r.json()\n",
    "\n",
    "    # conversion rate and reward\n",
    "    if d['reward'] > 0:\n",
    "        rate += 1\n",
    "        reward += d['reward']\n",
    "        \n",
    "    # model_three.retrain(reward)\n",
    "    \n",
    "    # update next state\n",
    "    next_state = d['state']\n",
    "    \n",
    "print('Conversion rate is:', rate/episodes)\n",
    "print('Average reward is:', reward/episodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
