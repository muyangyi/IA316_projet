{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:23:42.754757Z",
     "start_time": "2019-02-24T18:23:40.001281Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import sleep\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Concatenate, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:01.604890Z",
     "start_time": "2019-02-24T18:24:01.601792Z"
    }
   },
   "outputs": [],
   "source": [
    "user_id = '0EFZ3W3H6IQRD9DDSPS2'\n",
    "base_url = 'http://35.180.254.42'\n",
    "url_reset = base_url + '/reset'\n",
    "url_predict = base_url + '/predict'\n",
    "params = {'user_id': user_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:03.816188Z",
     "start_time": "2019-02-24T18:24:02.711149Z"
    }
   },
   "outputs": [],
   "source": [
    "# json file\n",
    "r = requests.get(url=url_reset, params=params)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:03.861786Z",
     "start_time": "2019-02-24T18:24:03.853199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item_history', 'nb_items', 'nb_users', 'next_item', 'next_user', 'next_variables', 'rating_history', 'user_history', 'variables_history'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:05.394756Z",
     "start_time": "2019-02-24T18:24:05.389327Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_items = data['nb_items']\n",
    "nb_users = data['nb_users']\n",
    "nb_variables = len(data['variables_history'][0])\n",
    "\n",
    "user_history = data['user_history']\n",
    "item_history = data['item_history']\n",
    "rating_history = data['rating_history']\n",
    "variables_history = np.array(data['variables_history'])\n",
    "\n",
    "next_user = data['next_user']\n",
    "next_item = data['next_item']\n",
    "next_variables = data['next_variables']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:09.003706Z",
     "start_time": "2019-02-24T18:24:08.861195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 30)        3030        user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 30)        9030        item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 30)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 30)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "variable (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 65)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 variable[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           1320        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            21          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,401\n",
      "Trainable params: 13,401\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # For each sample we input the integer identifiers\n",
    "# of a single user and a single item\n",
    "user_id_input = Input(shape=[1], name='user')\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "variable_input = Input(shape=[5], name='variable')\n",
    "\n",
    "embedding_size = 30\n",
    "user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "# reshape from shape: (batch_size, input_length, embedding_size)\n",
    "# to shape: (batch_size, input_length * embedding_size) which is\n",
    "# equal to shape: (batch_size, embedding_size)\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "cc = Concatenate()([user_vecs, item_vecs, variable_input])\n",
    "\n",
    "y = Dense(20, activation='relu')(cc)\n",
    "\n",
    "yy = Dense(1, activation='relu')(y)\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input, variable_input], outputs=yy)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:13.572803Z",
     "start_time": "2019-02-24T18:24:10.821289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/80\n",
      "1800/1800 [==============================] - 0s 144us/step - loss: 8.5952 - val_loss: 6.1603\n",
      "Epoch 2/80\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 4.9797 - val_loss: 3.3033\n",
      "Epoch 3/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 2.9951 - val_loss: 2.3983\n",
      "Epoch 4/80\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 2.5073 - val_loss: 2.1420\n",
      "Epoch 5/80\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 2.2146 - val_loss: 1.8997\n",
      "Epoch 6/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 1.9013 - val_loss: 1.6447\n",
      "Epoch 7/80\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 1.5990 - val_loss: 1.4193\n",
      "Epoch 8/80\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 1.3375 - val_loss: 1.2477\n",
      "Epoch 9/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 1.1281 - val_loss: 1.1183\n",
      "Epoch 10/80\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.9712 - val_loss: 1.0312\n",
      "Epoch 11/80\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.8526 - val_loss: 0.9613\n",
      "Epoch 12/80\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.7653 - val_loss: 0.9149\n",
      "Epoch 13/80\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.6996 - val_loss: 0.8827\n",
      "Epoch 14/80\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.6516 - val_loss: 0.8542\n",
      "Epoch 15/80\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.6137 - val_loss: 0.8423\n",
      "Epoch 16/80\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.5853 - val_loss: 0.8222\n",
      "Epoch 17/80\n",
      "1800/1800 [==============================] - 0s 31us/step - loss: 0.5612 - val_loss: 0.8114\n",
      "Epoch 18/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.5413 - val_loss: 0.7927\n",
      "Epoch 19/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.5248 - val_loss: 0.7810\n",
      "Epoch 20/80\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.5114 - val_loss: 0.7793\n",
      "Epoch 21/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.4980 - val_loss: 0.7627\n",
      "Epoch 22/80\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.4890 - val_loss: 0.7658\n",
      "Epoch 23/80\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.4808 - val_loss: 0.7592\n",
      "Epoch 24/80\n",
      "1800/1800 [==============================] - 0s 42us/step - loss: 0.4720 - val_loss: 0.7420\n",
      "Epoch 25/80\n",
      "1800/1800 [==============================] - 0s 39us/step - loss: 0.4648 - val_loss: 0.7469\n",
      "Epoch 26/80\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.4606 - val_loss: 0.7370\n",
      "Epoch 27/80\n",
      "1800/1800 [==============================] - 0s 30us/step - loss: 0.4557 - val_loss: 0.7343\n",
      "Epoch 28/80\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.4499 - val_loss: 0.7282\n",
      "Epoch 29/80\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.4469 - val_loss: 0.7229\n",
      "Epoch 30/80\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.4436 - val_loss: 0.7146\n",
      "Epoch 31/80\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.4396 - val_loss: 0.7133\n",
      "Epoch 32/80\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.4365 - val_loss: 0.7112\n",
      "Epoch 33/80\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.4352 - val_loss: 0.7064\n",
      "Epoch 34/80\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.4312 - val_loss: 0.7028\n",
      "Epoch 35/80\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.4297 - val_loss: 0.7004\n",
      "Epoch 36/80\n",
      "1800/1800 [==============================] - 0s 16us/step - loss: 0.4263 - val_loss: 0.7016\n",
      "Epoch 37/80\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.4260 - val_loss: 0.6965\n",
      "Epoch 38/80\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.4220 - val_loss: 0.6919\n",
      "Epoch 39/80\n",
      "1800/1800 [==============================] - 0s 30us/step - loss: 0.4212 - val_loss: 0.6923\n",
      "Epoch 40/80\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.4194 - val_loss: 0.6867\n",
      "Epoch 41/80\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.4169 - val_loss: 0.6959\n",
      "Epoch 42/80\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.4160 - val_loss: 0.6902\n",
      "Epoch 43/80\n",
      "1800/1800 [==============================] - 0s 32us/step - loss: 0.4136 - val_loss: 0.6891\n",
      "Epoch 44/80\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.4122 - val_loss: 0.6885\n",
      "Epoch 45/80\n",
      "1800/1800 [==============================] - 0s 30us/step - loss: 0.4103 - val_loss: 0.6849\n",
      "Epoch 46/80\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.4086 - val_loss: 0.6875\n",
      "Epoch 47/80\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.4074 - val_loss: 0.6833\n",
      "Epoch 48/80\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.4053 - val_loss: 0.6809\n",
      "Epoch 49/80\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.4034 - val_loss: 0.6789\n",
      "Epoch 50/80\n",
      "1800/1800 [==============================] - 0s 39us/step - loss: 0.4027 - val_loss: 0.6750\n",
      "Epoch 51/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.4008 - val_loss: 0.6771\n",
      "Epoch 52/80\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.3992 - val_loss: 0.6716\n",
      "Epoch 53/80\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.3976 - val_loss: 0.6691\n",
      "Epoch 54/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.3962 - val_loss: 0.6692\n",
      "Epoch 55/80\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.3948 - val_loss: 0.6677\n",
      "Epoch 56/80\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.3938 - val_loss: 0.6743\n",
      "Epoch 57/80\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.3921 - val_loss: 0.6681\n",
      "Epoch 58/80\n",
      "1800/1800 [==============================] - 0s 35us/step - loss: 0.3905 - val_loss: 0.6746\n",
      "Epoch 59/80\n",
      "1800/1800 [==============================] - 0s 36us/step - loss: 0.3917 - val_loss: 0.6662\n",
      "Epoch 60/80\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.3883 - val_loss: 0.6657\n",
      "Epoch 61/80\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.3862 - val_loss: 0.6720\n",
      "Epoch 62/80\n",
      "1800/1800 [==============================] - 0s 16us/step - loss: 0.3845 - val_loss: 0.6743\n",
      "Epoch 63/80\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.3831 - val_loss: 0.6682\n",
      "Epoch 64/80\n",
      "1800/1800 [==============================] - 0s 36us/step - loss: 0.3818 - val_loss: 0.6729\n",
      "Epoch 65/80\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.3789 - val_loss: 0.6682\n",
      "Epoch 66/80\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.3789 - val_loss: 0.6664\n",
      "Epoch 67/80\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.3759 - val_loss: 0.6634\n",
      "Epoch 68/80\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.3757 - val_loss: 0.6650\n",
      "Epoch 69/80\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.3742 - val_loss: 0.6658\n",
      "Epoch 70/80\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.3716 - val_loss: 0.6586\n",
      "Epoch 71/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.3687 - val_loss: 0.6651\n",
      "Epoch 72/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.3674 - val_loss: 0.6647\n",
      "Epoch 73/80\n",
      "1800/1800 [==============================] - 0s 41us/step - loss: 0.3660 - val_loss: 0.6609\n",
      "Epoch 74/80\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.3637 - val_loss: 0.6630\n",
      "Epoch 75/80\n",
      "1800/1800 [==============================] - 0s 43us/step - loss: 0.3623 - val_loss: 0.6642\n",
      "Epoch 76/80\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.3607 - val_loss: 0.6609\n",
      "Epoch 77/80\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.3585 - val_loss: 0.6633\n",
      "Epoch 78/80\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.3572 - val_loss: 0.6650\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 0s 30us/step - loss: 0.3548 - val_loss: 0.6591\n",
      "Epoch 80/80\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.3526 - val_loss: 0.6653\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adamax', loss='mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "history = model.fit([user_history, item_history, variables_history], rating_history,\n",
    "                    batch_size=64, epochs=80, validation_split=0.1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:31.675530Z",
     "start_time": "2019-02-24T18:24:13.861298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  0.7429839905947659\n",
      "mae:  0.677650551199913\n"
     ]
    }
   ],
   "source": [
    "nb_samples = 100\n",
    "mse, mae = 0, 0\n",
    "prediction = 3 # baseline\n",
    "\n",
    "for i in range(nb_samples):\n",
    "    sleep(0.05)\n",
    "    r = requests.get(url=url_predict, params=params)\n",
    "    d = r.json()\n",
    "\n",
    "    # error for last prediction\n",
    "    rating = d['rating']\n",
    "    mse += (rating - prediction) ** 2\n",
    "    mae += np.abs(rating - prediction)\n",
    "    \n",
    "    # predict next\n",
    "    next_user = d['next_user']\n",
    "    next_item = d['next_item']\n",
    "    next_variables = d['next_variables']\n",
    "    prediction = model.predict([[next_user], [next_item], [next_variables]])[0][0]\n",
    "\n",
    "print('mse: ', mse/nb_samples)\n",
    "print('mae: ', mae/nb_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:38.453510Z",
     "start_time": "2019-02-24T18:24:38.402638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 30)        3030        user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 30)        9030        item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 30)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 30)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,060\n",
      "Trainable params: 12,060\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # For each sample we input the integer identifiers\n",
    "# of a single user and a single item\n",
    "user_id_input = Input(shape=[1], name='user')\n",
    "item_id_input = Input(shape=[1], name='item')\n",
    "variable_input = Input(shape=[5], name='variable')\n",
    "\n",
    "embedding_size = 30\n",
    "user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "\n",
    "item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "\n",
    "# reshape from shape: (batch_size, input_length, embedding_size)\n",
    "# to shape: (batch_size, input_length * embedding_size) which is\n",
    "# equal to shape: (batch_size, embedding_size)\n",
    "user_vecs = Flatten()(user_embedding)\n",
    "item_vecs = Flatten()(item_embedding)\n",
    "\n",
    "y = Dot(axes=1)([user_vecs, item_vecs])\n",
    "\n",
    "# cc = Concatenate()([y, variable_input])\n",
    "\n",
    "# yy = Dense(1, activation='relu')(cc)\n",
    "\n",
    "model = Model(inputs=[user_id_input, item_id_input, variable_input], outputs=y)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:40.962003Z",
     "start_time": "2019-02-24T18:24:39.070345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/60\n",
      "1800/1800 [==============================] - 0s 97us/step - loss: 10.1307 - val_loss: 10.1922\n",
      "Epoch 2/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 10.1162 - val_loss: 10.1913\n",
      "Epoch 3/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 10.1051 - val_loss: 10.1900\n",
      "Epoch 4/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 10.0930 - val_loss: 10.1881\n",
      "Epoch 5/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 10.0792 - val_loss: 10.1851\n",
      "Epoch 6/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 10.0632 - val_loss: 10.1810\n",
      "Epoch 7/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 10.0447 - val_loss: 10.1755\n",
      "Epoch 8/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 10.0231 - val_loss: 10.1674\n",
      "Epoch 9/60\n",
      "1800/1800 [==============================] - 0s 12us/step - loss: 9.9981 - val_loss: 10.1576\n",
      "Epoch 10/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 9.9696 - val_loss: 10.1454\n",
      "Epoch 11/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 9.9372 - val_loss: 10.1302\n",
      "Epoch 12/60\n",
      "1800/1800 [==============================] - 0s 16us/step - loss: 9.9007 - val_loss: 10.1120\n",
      "Epoch 13/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 9.8600 - val_loss: 10.0906\n",
      "Epoch 14/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 9.8147 - val_loss: 10.0644\n",
      "Epoch 15/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 9.7639 - val_loss: 10.0345\n",
      "Epoch 16/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 9.7082 - val_loss: 10.0000\n",
      "Epoch 17/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 9.6475 - val_loss: 9.9614\n",
      "Epoch 18/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 9.5807 - val_loss: 9.9180\n",
      "Epoch 19/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 9.5095 - val_loss: 9.8712\n",
      "Epoch 20/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 9.4327 - val_loss: 9.8184\n",
      "Epoch 21/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 9.3493 - val_loss: 9.7617\n",
      "Epoch 22/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 9.2609 - val_loss: 9.7001\n",
      "Epoch 23/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 9.1676 - val_loss: 9.6328\n",
      "Epoch 24/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 9.0678 - val_loss: 9.5616\n",
      "Epoch 25/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 8.9646 - val_loss: 9.4856\n",
      "Epoch 26/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 8.8555 - val_loss: 9.4064\n",
      "Epoch 27/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 8.7421 - val_loss: 9.3214\n",
      "Epoch 28/60\n",
      "1800/1800 [==============================] - 0s 12us/step - loss: 8.6241 - val_loss: 9.2339\n",
      "Epoch 29/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 8.5027 - val_loss: 9.1439\n",
      "Epoch 30/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 8.3781 - val_loss: 9.0480\n",
      "Epoch 31/60\n",
      "1800/1800 [==============================] - 0s 12us/step - loss: 8.2499 - val_loss: 8.9484\n",
      "Epoch 32/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 8.1173 - val_loss: 8.8445\n",
      "Epoch 33/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 7.9808 - val_loss: 8.7358\n",
      "Epoch 34/60\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 7.8406 - val_loss: 8.6232\n",
      "Epoch 35/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 7.6980 - val_loss: 8.5052\n",
      "Epoch 36/60\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 7.5491 - val_loss: 8.3858\n",
      "Epoch 37/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 7.3994 - val_loss: 8.2615\n",
      "Epoch 38/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 7.2481 - val_loss: 8.1347\n",
      "Epoch 39/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 7.0932 - val_loss: 8.0052\n",
      "Epoch 40/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 6.9384 - val_loss: 7.8739\n",
      "Epoch 41/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 6.7822 - val_loss: 7.7369\n",
      "Epoch 42/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 6.6239 - val_loss: 7.6007\n",
      "Epoch 43/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 6.4655 - val_loss: 7.4596\n",
      "Epoch 44/60\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 6.3050 - val_loss: 7.3165\n",
      "Epoch 45/60\n",
      "1800/1800 [==============================] - 0s 16us/step - loss: 6.1431 - val_loss: 7.1689\n",
      "Epoch 46/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 5.9804 - val_loss: 7.0226\n",
      "Epoch 47/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 5.8181 - val_loss: 6.8746\n",
      "Epoch 48/60\n",
      "1800/1800 [==============================] - 0s 12us/step - loss: 5.6563 - val_loss: 6.7273\n",
      "Epoch 49/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 5.4947 - val_loss: 6.5751\n",
      "Epoch 50/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 5.3357 - val_loss: 6.4260\n",
      "Epoch 51/60\n",
      "1800/1800 [==============================] - 0s 16us/step - loss: 5.1782 - val_loss: 6.2749\n",
      "Epoch 52/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 5.0215 - val_loss: 6.1244\n",
      "Epoch 53/60\n",
      "1800/1800 [==============================] - 0s 15us/step - loss: 4.8659 - val_loss: 5.9755\n",
      "Epoch 54/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 4.7130 - val_loss: 5.8236\n",
      "Epoch 55/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 4.5608 - val_loss: 5.6750\n",
      "Epoch 56/60\n",
      "1800/1800 [==============================] - 0s 16us/step - loss: 4.4121 - val_loss: 5.5285\n",
      "Epoch 57/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 4.2664 - val_loss: 5.3830\n",
      "Epoch 58/60\n",
      "1800/1800 [==============================] - 0s 13us/step - loss: 4.1243 - val_loss: 5.2396\n",
      "Epoch 59/60\n",
      "1800/1800 [==============================] - 0s 14us/step - loss: 3.9846 - val_loss: 5.0988\n",
      "Epoch 60/60\n",
      "1800/1800 [==============================] - 0s 12us/step - loss: 3.8476 - val_loss: 4.9592\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adamax', loss='mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "history = model.fit([user_history, item_history, variables_history], rating_history,\n",
    "                    batch_size=64, epochs=60, validation_split=0.1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-24T18:24:57.723216Z",
     "start_time": "2019-02-24T18:24:40.997056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:  4.866380674852802\n",
      "mae:  1.8361245712637901\n"
     ]
    }
   ],
   "source": [
    "nb_samples = 100\n",
    "mse, mae = 0, 0\n",
    "prediction = 3 # baseline\n",
    "\n",
    "for i in range(nb_samples):\n",
    "    sleep(0.05)\n",
    "    r = requests.get(url=url_predict, params=params)\n",
    "    d = r.json()\n",
    "\n",
    "    # error for last prediction\n",
    "    rating = d['rating']\n",
    "    mse += (rating - prediction) ** 2\n",
    "    mae += np.abs(rating - prediction)\n",
    "    \n",
    "    # predict next\n",
    "    next_user = d['next_user']\n",
    "    next_item = d['next_item']\n",
    "    next_variables = d['next_variables']\n",
    "    prediction = model.predict([[next_user], [next_item], [next_variables]])[0][0]\n",
    "\n",
    "print('mse: ', mse/nb_samples)\n",
    "print('mae: ', mae/nb_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
